{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data set for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.path.join('.'))\n",
    "module_path = os.path.abspath(os.path.join('..'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_prep;\n",
    "import utils;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en, data_hi = data_prep.loadParallelCorpus('../../data/parallel/IITB.en-hi.en', '../../data/parallel/IITB.en-hi.hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561841, 1561841)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_rows=data_en.split(\"\\n\")\n",
    "hi_rows=data_hi.split(\"\\n\")\n",
    "(len(en_rows),len(hi_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Shuffle corpora. The sentences in the corpora are not mixed up in the original order\n",
    "en_rows_all, hi_rows_all = data_prep.shuffle(en_rows, hi_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(en_sentences, hi_sentences):\n",
    "    en_sentences = [ line.lower() for line in en_sentences]\n",
    "    \n",
    "    en_vocab_dict = data_prep.buildEngVocab(en_sentences)\n",
    "    hi_vocab_dict = data_prep.buildHinVocab(hi_sentences)\n",
    "\n",
    "    en_vocab = list(map(lambda x: x[0], sorted(en_vocab_dict.items(), key=lambda x: -x[1])))\n",
    "    hi_vocab = list(map(lambda x: x[0], sorted(hi_vocab_dict.items(), key=lambda x: -x[1])))\n",
    "    \n",
    "    # Zipf's law\n",
    "    # https://openreview.net/pdf?id=Bk8N0RLxx - limit vocab to 50k\n",
    "    if (len(en_vocab) > 50000):\n",
    "      en_vocab = en_vocab[:50000]\n",
    "    if (len(hi_vocab) > 50000):\n",
    "      hi_vocab = hi_vocab[:50000]\n",
    "\n",
    "    # Build a Word to Index Dictionary for English\n",
    "    start_idx = 4\n",
    "    en_word2idx = dict([(word, idx + start_idx) for idx, word in enumerate(en_vocab)])\n",
    "    en_word2idx['<ukn>'] = 0  # Unknown words\n",
    "    en_word2idx['<start>'] = 1\n",
    "    en_word2idx['<end>'] = 2  # End of sentence\n",
    "    en_word2idx['<pad>'] = 3  # Padding\n",
    "\n",
    "    en_vocab.append('<ukn>');\n",
    "    en_vocab.append('<start>');\n",
    "    en_vocab.append('<end>');\n",
    "    en_vocab.append('<pad>');\n",
    "    \n",
    "    # Build reverse Index to Word Dictionary for English using the already created Word to Index Dictionary\n",
    "    en_idx2word = dict([(idx, word) for word, idx in en_word2idx.items()])\n",
    "\n",
    "    # Build a Word to Index Dictionary for Hindi\n",
    "    start_idx = 4\n",
    "    hi_word2idx = dict([(word, idx + start_idx) for idx, word in enumerate(hi_vocab)])\n",
    "    hi_word2idx['<ukn>'] = 0  # Unknown\n",
    "    hi_word2idx['<start>'] = 1\n",
    "    hi_word2idx['<end>'] = 2  # End of sentence\n",
    "    hi_word2idx['<pad>'] = 3  # Padding\n",
    "\n",
    "    hi_vocab.append('<ukn>');\n",
    "    hi_vocab.append('<start>');\n",
    "    hi_vocab.append('<end>');\n",
    "    hi_vocab.append('<pad>');\n",
    "\n",
    "    \n",
    "    # Build the inverse Index to Word Dictionary for Hindi using the already created Word to Index Dictionary\n",
    "    hi_idx2word = dict([(idx, word) for word, idx in hi_word2idx.items()])\n",
    "\n",
    "    # Encode words in senteces by their index in Vocabulary\n",
    "    x = [[en_word2idx.get(word.strip(',.\" ;:)(][?!'), 3) for word in sentence.split()] for sentence in en_sentences]\n",
    "    y = [[hi_word2idx.get(word.strip(',.\" ;:)(।|][?!'), 3) for word in sentence.split()] for sentence in hi_sentences]\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(x)):\n",
    "        n1 = len(x[i])\n",
    "        n2 = len(y[i])\n",
    "        n = n1 if n1 < n2 else n2\n",
    "        if abs(n1 - n2) < 0.3 * n:\n",
    "            if n1 <= max_sent_length and n2 <= max_sent_length:\n",
    "                X.append(x[i])\n",
    "                Y.append(y[i])\n",
    "\n",
    "    return X, Y, en_word2idx, en_idx2word, en_vocab, hi_word2idx, hi_idx2word, hi_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save_location = \"out/parallel_trainv1.p\"\n",
    "utils.save_pickle(dataset_save_location, prepare_dataset(en_rows_all, hi_rows_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704153, 704153, 50004, 50004)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us load and check for sanity\n",
    "X_all, Y_all, en_word2idx_all, en_idx2word_all, en_vocab_all, hi_word2idx_all, hi_idx2word_all, hi_vocab_all = utils.load_pickle_dataset(dataset_save_location)\n",
    "len(X_all), len(Y_all), len(en_vocab_all), len(hi_vocab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linguistics a form of humanity <pad> - linguistics is called \n",
      "\n",
      "इसका एक रूप मानवजाति भाषा विज्ञान <pad> कहलाता है \n",
      "\n",
      "> 2 - <pad> <pad> subject to minimum net premium of <pad> payable by farmer \n",
      "\n",
      "<pad> <pad> <pad> बशर्ते <pad> न्यूनतम निवल प्रीमियम कृषक द्वारा देय हो \n",
      "\n",
      "<pad> \n",
      "\n",
      "<pad> \n",
      "\n",
      "<pad> da <pad> \n",
      "\n",
      "<pad> दा <pad> \n",
      "\n",
      "united kingdom \n",
      "\n",
      "यूनाइटेड <pad> \n",
      "\n",
      "utc \n",
      "\n",
      "UTC \n",
      "\n",
      "& collapse thread \n",
      "\n",
      "à¤¯à¤¹à¤¾à¤ à¤à¤¿à¤¸à¤à¤¾à¤à¤ M \n",
      "\n",
      "nothing happens unless first a dream ” - carl <pad> 1878 - 1967 poet \n",
      "\n",
      "“कोई सपना देखे बिना कुछ नहीं होता ”-कार्ल <pad> <pad> कवि \n",
      "\n",
      "a special purpose vehicle has been constituted to take up highway projects \n",
      "\n",
      "राजमार्ग परियोजनाओं के निर्माण के लिए एक विशेष प्रयोजन <pad> का सृजन किया गया है \n",
      "\n",
      "i end up at five \n",
      "\n",
      "मैं ५ पर जाकर <pad> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    data_prep.printSentence(X_all[n], en_idx2word_all)\n",
    "    print(\"\\n\")\n",
    "    data_prep.printSentence(Y_all[n], hi_idx2word_all)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
