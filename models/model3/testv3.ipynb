{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testv3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptripathi/NLP/blob/master/models/model3/testv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JChQPITdb5Fk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing the encoder-decoder model"
      ]
    },
    {
      "metadata": {
        "id": "N2eFMi29b84w",
        "colab_type": "code",
        "outputId": "f0d1ea98-2eef-4213-ee3a-7550f61d30bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "crD66FeMcAni",
        "colab_type": "code",
        "outputId": "4399c63c-962e-4884-d83b-b114328e965a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7JicSSOpcEZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6I2evay6cH7k",
        "colab_type": "code",
        "outputId": "7c870953-08ac-4855-97aa-81fcd12ce99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WB5OFOqbcKfK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "current_path = os.path.abspath(os.path.join('.'))\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7IosKiWqcVYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_save_location = \"/content/gdrive/My Drive/W266/Project/data/parallel_trainv3.p\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7z6xHouclTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import data_prep;\n",
        "import utils;\n",
        "import encoder;\n",
        "import attention;\n",
        "import decoder;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Dg3sLueceB2",
        "colab_type": "code",
        "outputId": "54f49cc2-2f23-4a6f-96a5-dfee8b19de25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_all, Y_all, en_word2idx_all, en_idx2word_all, en_vocab_all, hi_word2idx_all, hi_idx2word_all, hi_vocab_all = utils.load_pickle_dataset(dataset_save_location)\n",
        "len(X_all), len(Y_all), len(en_vocab_all), len(hi_vocab_all)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(696695, 696695, 50004, 50004)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "x9hLN_N9cn1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb_dim = 100\n",
        "embedding_weights = utils.load_glove_embeddings(\"/content/gdrive/My Drive/W266/Project/data/glove.6B/\", len(en_vocab_all), en_word2idx_all, emb_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gb7eECAacvtw",
        "colab_type": "code",
        "outputId": "6a4bb0bc-785a-4ea5-e720-f3ba4d2d7eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_length_inp = utils.max_length(X_all) + 2 # <start>, <end>\n",
        "max_length_tar = utils.max_length(Y_all) + 2 # <start>, <end>\n",
        "(max_length_inp, max_length_tar)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "pvAqIBKodRuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "embedding_dim = 100\n",
        "units = 1024\n",
        "vocab_inp_size = len(en_vocab_all)\n",
        "vocab_tar_size = len(hi_vocab_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Y3ctzsZdZjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from encoder import Encoder\n",
        "from decoder import Decoder\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE, weights_ = embedding_weights,mask=1)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YW4_6K3Qd-kY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gqNXjDceGON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/gdrive/My Drive/W266/Project/training_checkpoints_v3'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7hYOTXjeIDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "    sentence = '<start> ' + sentence.lower() + ' <end>'\n",
        "    \n",
        "    inputs = [en_word2idx_all[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    \n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "    \n",
        "    hidden = [tf.zeros((1,units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([hi_word2idx_all['<start>']], 0)\n",
        "    \n",
        "    \n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weigths to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        \n",
        "        #word_preds = np.argsort(predictions[-3])\n",
        "        #print(word_preds)\n",
        "        #for ii in len(word_preds):\n",
        "        #  print(hi_idx2word_all[ii])\n",
        "\n",
        "        \n",
        "        result += hi_idx2word_all[predicted_id] + ' '\n",
        "\n",
        "        if hi_idx2word_all[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A9rbHGDRePGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(sentence, encoder, decoder, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, max_length_inp, max_length_targ)\n",
        "        \n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C2_Eby_geVeQ",
        "colab_type": "code",
        "outputId": "7b26ab18-f7a5-4c1f-84c5-648f18adfed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb1b0350c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "frvil-iTeaDA",
        "colab_type": "code",
        "outputId": "09fdbda1-0ac2-4966-f113-b8259a17fb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "translate('i love this course', encoder, decoder, max_length_inp, max_length_tar)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> i love this course <end>\n",
            "Predicted translation: मैं तो मैं नहा <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xio1Biw_LWAl",
        "colab_type": "code",
        "outputId": "6b88ed5a-5828-4002-e44a-4c682e5f60a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  5000400   \n",
            "_________________________________________________________________\n",
            "unified_gru_4 (UnifiedGRU)   multiple                  3459072   \n",
            "_________________________________________________________________\n",
            "unified_gru_5 (UnifiedGRU)   multiple                  6297600   \n",
            "=================================================================\n",
            "Total params: 14,757,072\n",
            "Trainable params: 9,756,672\n",
            "Non-trainable params: 5,000,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BY8aRgq-LXpF",
        "colab_type": "code",
        "outputId": "60ea8ab6-a728-4f52-d018-e13ca568b38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "decoder.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  5000400   \n",
            "_________________________________________________________________\n",
            "unified_gru_6 (UnifiedGRU)   multiple                  6604800   \n",
            "_________________________________________________________________\n",
            "unified_gru_7 (UnifiedGRU)   multiple                  6297600   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  51254100  \n",
            "_________________________________________________________________\n",
            "attention_1 (Attention)      multiple                  2100225   \n",
            "=================================================================\n",
            "Total params: 71,257,125\n",
            "Trainable params: 71,257,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-pbry1HTe7hB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test = X_all[50000:55000]\n",
        "Y_test = Y_all[50000:55000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ie97g3fte--R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_sen = []\n",
        "Y_test_sen = []\n",
        "\n",
        "sents = []\n",
        "for n in range(len(X_test)):\n",
        "  sent_X = ' '.join(en_idx2word_all[X_test[n][i]] for i in range(len(X_test[n])))\n",
        "  sent_Y = ' '.join(hi_idx2word_all[Y_test[n][i]] for i in range(len(Y_test[n])))\n",
        "  X_test_sen.append(sent_X.strip())\n",
        "  Y_test_sen.append(sent_Y.strip())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_rG4Ur8fHIt",
        "colab_type": "code",
        "outputId": "0dcd7770-2445-4a3c-d522-e023c369beaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "(len(X_test_sen), len(Y_test_sen), X_test_sen[200], Y_test_sen[200])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000,\n",
              " 5000,\n",
              " 'error adding <ukn> <ukn> 2 <ukn> 3',\n",
              " '<ukn> 1 को जोड़ने में <ukn> 2 <ukn> 3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "p3RCcu0RfNL8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for n in range(len(X_test)):\n",
        "  X_test[n] = [en_word2idx_all['<start>']] + X_test[n] + [en_word2idx_all['<end>']]\n",
        "test_input_tensor = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                                maxlen=max_length_inp,\n",
        "                                                                padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1Ftr3h3fS4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76d71552-4e55-48ce-8b86-a731f6fa3480"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import codecs\n",
        "test_file = '/content/gdrive/My Drive/W266/Project/test_results.txt'\n",
        "fp = codecs.open(test_file, encoding=\"utf-8\", mode=\"w\")\n",
        "\n",
        "for i, test_sent in enumerate(X_test_sen):\n",
        "  res, _, _ = evaluate(test_sent, encoder, decoder, max_length_inp, max_length_tar)\n",
        "  fp.write(test_sent)\n",
        "  fp.write('\\t\\t')\n",
        "  fp.write(Y_test_sen[i])\n",
        "  fp.write('\\t\\t')  \n",
        "  fp.write(res.strip().rsplit(' ', 1)[0])\n",
        "  fp.write('\\n')\n",
        "  \n",
        "fp.close()\n",
        "  "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24min 47s, sys: 2min 52s, total: 27min 40s\n",
            "Wall time: 26min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oFJ5-bIMgr1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3b8f727-6457-4f6d-b5a2-8b1c925560a4"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_contents = []\n",
        "\n",
        "with codecs.open(test_file, encoding=\"utf-8\", mode=\"r\") as fp:\n",
        "  i = 0\n",
        "  line = fp.readline()\n",
        "  while len(line.strip()) > 0:      \n",
        "      comps = re.split(r'\\t+', line.rstrip('\\n'))\n",
        "      if (len(comps) > 2):\n",
        "        file_content = [comps[1], comps[2]]\n",
        "        file_contents.append(file_content)\n",
        "        line = fp.readline()\n",
        "      else:\n",
        "          print(line)\n",
        "          line = fp.readline()\n",
        "\n",
        "      i = i + 1\n",
        "      \n",
        "      \n",
        "print(len(file_contents))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HqFLvLpMgbnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import score;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s5Hq7-I0glFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f779ae7-ed10-4daf-b819-5f0beca966e1"
      },
      "cell_type": "code",
      "source": [
        "print(score.getBlueScore(file_contents))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22261762523270248\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}